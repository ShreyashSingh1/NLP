{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\shrey\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\shrey\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cat is in the box. The cat likes the box. The box is over the cat.\\nwe are the champions my friend! we will keep on fighting till the end.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \"\"\"The cat is in the box. The cat likes the box. The box is over the cat.\n",
    "we are the champions my friend! we will keep on fighting till the end.\"\"\"\n",
    "\n",
    "corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Pragraph -> Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The cat is in the box.',\n",
       " 'The cat likes the box.',\n",
       " 'The box is over the cat.',\n",
       " 'we are the champions my friend!',\n",
       " 'we will keep on fighting till the end.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "documents = sent_tokenize(corpus)\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pragraph -> Words\n",
    "- Sentences -> Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'cat',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box',\n",
       " '.',\n",
       " 'The',\n",
       " 'cat',\n",
       " 'likes',\n",
       " 'the',\n",
       " 'box',\n",
       " '.',\n",
       " 'The',\n",
       " 'box',\n",
       " 'is',\n",
       " 'over',\n",
       " 'the',\n",
       " 'cat',\n",
       " '.',\n",
       " 'we',\n",
       " 'are',\n",
       " 'the',\n",
       " 'champions',\n",
       " 'my',\n",
       " 'friend',\n",
       " '!',\n",
       " 'we',\n",
       " 'will',\n",
       " 'keep',\n",
       " 'on',\n",
       " 'fighting',\n",
       " 'till',\n",
       " 'the',\n",
       " 'end',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(corpus)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'cat',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box',\n",
       " '.',\n",
       " 'The',\n",
       " 'cat',\n",
       " 'likes',\n",
       " 'the',\n",
       " 'box',\n",
       " '.',\n",
       " 'The',\n",
       " 'box',\n",
       " 'is',\n",
       " 'over',\n",
       " 'the',\n",
       " 'cat',\n",
       " '.',\n",
       " 'we',\n",
       " 'are',\n",
       " 'the',\n",
       " 'champions',\n",
       " 'my',\n",
       " 'friend',\n",
       " '!',\n",
       " 'we',\n",
       " 'will',\n",
       " 'keep',\n",
       " 'on',\n",
       " 'fighting',\n",
       " 'till',\n",
       " 'the',\n",
       " 'end',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'cat',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'box.',\n",
       " 'The',\n",
       " 'cat',\n",
       " 'likes',\n",
       " 'the',\n",
       " 'box.',\n",
       " 'The',\n",
       " 'box',\n",
       " 'is',\n",
       " 'over',\n",
       " 'the',\n",
       " 'cat.',\n",
       " 'we',\n",
       " 'are',\n",
       " 'the',\n",
       " 'champions',\n",
       " 'my',\n",
       " 'friend',\n",
       " '!',\n",
       " 'we',\n",
       " 'will',\n",
       " 'keep',\n",
       " 'on',\n",
       " 'fighting',\n",
       " 'till',\n",
       " 'the',\n",
       " 'end',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fullstop is considered in same token\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "tokenizer.tokenize(corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
